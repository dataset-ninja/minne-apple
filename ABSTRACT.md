The authors of the **MinneApple: A Benchmark Dataset for Apple Detection and Segmentation** introduce claim the need for advancing the current state-of-the-art in fruit detection, segmentation, and counting, particularly within orchard environments. This aim is pursued by offering an extensive collection of high-resolution images captured in orchards, complemented by human-generated annotations for the fruits present on the trees. The dataset serves a dual purpose, addressing two distinct subproblems integral to the broader challenge of yield estimation. Accurate fruit detection is essential for yield estimation, with the added complexity of clustered fruits necessitating a separate counting algorithm in most instances. Notably, *apple* objects are delineated with polygon masks, facilitating precise object detection, localization, and segmentation. Furthermore, the dataset includes data suitable for patch-based counting of clustered fruits, encompassing over 40,000 annotated object instances distributed across 1,000 images.

The data collection process primarily involves the capture of video footage from various sections of the orchard. A standard Samsung Galaxy S4 cell phone was employed for this purpose. During data acquisition, the camera was oriented horizontally, focusing on a single side of a tree row. Subsequently, individual images were extracted from these video sequences.
